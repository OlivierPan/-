{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d20d63260840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# tokenize the sentence with the BERT tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarked_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print out the tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BERT input:\n",
    "1 sentence or 2 sentences - \n",
    "for 2 sentence: [cls] The man went to the store . [SEP] He bought a dog .\n",
    "for 1 sentence: [cls] The man went down the street . [SEP]\n",
    "\"\"\"\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# tokenize the sentence with the BERT tokenizer\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# print out the tokens\n",
    "print(tokenized_text)\n",
    "\n",
    "# ['here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.']\n",
    "\n",
    "# some examples of the tokens contained in the vocab\n",
    "\n",
    "list(tokenizer.vocab.keys())[5000:5020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After stealing money from the bank, the bank robber was seen fishing ont \"\\\n",
    "\"the Mississippi river bank.\"\n",
    "print(text)\n",
    "\n",
    "# add special tokens\n",
    "marked_text = \"[CLS] \"+text+' [SEP]'\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# map the token strings to vocab indeces\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# display the tokens with indeces\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print(f'{tup[0]:<{12}} {tup[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the multiarray numpy extension module failed.  Most\nlikely you are trying to import a failed build of numpy.\nHere is how to proceed:\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n- If you are simply trying to use the numpy version that you have installed:\n  your installation is broken - please reinstall numpy.\n- If you have already reinstalled and that did not fix the problem, then:\n  1. Check that you are using the Python you expect (you're using /usr/local/opt/python/bin/python3.7),\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy versions you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n     Note: this error has many possible causes, so please don't comment on\n     an existing issue about this - open a new one instead.\n\nOriginal error was: dlopen(/Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so, 2): Symbol not found: _PyBuffer_Type\n  Referenced from: /Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so\n  Expected in: flat namespace\n in /Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so, 2): Symbol not found: _PyBuffer_Type\n  Referenced from: /Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so\n  Expected in: flat namespace\n in /Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a2dec89ad26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mOriginal\u001b[0m \u001b[0merror\u001b[0m \u001b[0mwas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \"\"\" % (sys.executable, exc)\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the multiarray numpy extension module failed.  Most\nlikely you are trying to import a failed build of numpy.\nHere is how to proceed:\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n- If you are simply trying to use the numpy version that you have installed:\n  your installation is broken - please reinstall numpy.\n- If you have already reinstalled and that did not fix the problem, then:\n  1. Check that you are using the Python you expect (you're using /usr/local/opt/python/bin/python3.7),\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy versions you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n     Note: this error has many possible causes, so please don't comment on\n     an existing issue about this - open a new one instead.\n\nOriginal error was: dlopen(/Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so, 2): Symbol not found: _PyBuffer_Type\n  Referenced from: /Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so\n  Expected in: flat namespace\n in /Users/pansa/Library/Python/3.7/lib/python/site-packages/numpy/core/_multiarray_umath.so\n"
     ]
    }
   ],
   "source": [
    "# mark each of the 22 tokens as belonging to sentence \"1\"\n",
    "segments_ids = [1]*len(tokenized_text)\n",
    "\n",
    "print(segments_ids)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "print(tokens_tensor)\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True,# whether the model returns all hidden-states\n",
    "                                  )\n",
    "# put the model in \"evaluation\" mode, meaning feed-forward operation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate BERT on example text, fetch the hidden states of the network\n",
    "# from 12 layers\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "  # evaluating the model will return a different number of objects based on\n",
    "  # how it's configured in the 'from_pretrained' call earlier\n",
    "  # in this case, because we set output_hidden_states=True, the third item will \n",
    "  # be the hidden states from all layers\n",
    "    hidden_states = outputs[2] # the third item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of layers:\", len(hidden_states))\n",
    "# output = 13 = initial embeddings + 12 BERT layers\n",
    "layer_i = 0\n",
    "print('Number of batches:', len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "print('Number of tokens:', len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "print('Number of hidden units:', len(hidden_states[layer_i][batch_i][token_i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word and sentence vectors\n",
    "# two ways\n",
    "token_vecs_cat = []\n",
    "# token_embeddings is a [22 *12 * 768] tensor\n",
    "# For each token in the sentence...\n",
    "\n",
    "for token in token_embeddings:\n",
    "# token is a [12 * 768] tensor\n",
    "# concatenate the vectors(that is, append them together) from the last four layers\n",
    "# each layer vector is 768 values, so 'cat_vec' is of length 3072\n",
    "  cat_vec = torch.cat((token[-1],token[-2],token[-3],token[-4]), dim=0)\n",
    "\n",
    "  # use 'cat_vec' to represent 'token'\n",
    "  token_vecs_cat.appebd(cat_vec)\n",
    "print(f\"Shape is {len(token_vecs_cat)}, {len(token_vecs_cat[0])}\") # 22 * 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence vector\n",
    "# hidden_states has shape [13 * 1 * 22 * 768]\n",
    "# 'token_vecs'.shape = [22 * 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "# hidden_states[-2] this is the second to last hidden layer of each token, size([1,22,768])\n",
    "# hidden_states[-2][0] eliminate the first batch\n",
    "token_vecs.shape\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "sentence_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1049', '1037', '2678', '18657', '1998']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import torch\n",
    "cosine(torch.rand(1,2),torch.rand(1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
